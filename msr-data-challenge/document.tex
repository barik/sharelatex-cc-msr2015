\documentclass[conference]{IEEEtran}
\usepackage{IEEEpreamble}

\usepackage{url}
\usepackage{booktabs}
\usepackage{csquotes}

\newcommand{\urlcount}{2,127,284}
\newcommand{\xlscount}{249,376}
\newcommand{\urlcountunique}{292,043}

\begin{document}


\title{A Quarter of Million Insights about End-User Programmers}

\author{
\IEEEauthorblockN{Kevin Lubick\IEEEauthorrefmark{2},
Titus Barik\IEEEauthorrefmark{1}\IEEEauthorrefmark{2},  
%Justin Smith\IEEEauthorrefmark{2}, 
%John Slankas\IEEEauthorrefmark{2}, 
Emerson Murphy-Hill\IEEEauthorrefmark{2}}
\IEEEauthorblockA{
\IEEEauthorrefmark{1}North Carolina State University, Raleigh, North Carolina, USA\\
\IEEEauthorrefmark{2}ABB Corporate Research, Raleigh, North Carolina, USA\\
titus.barik@us.abb.com, \{kjlubick, jssmit11, jbslanka\}@ncsu.edu, emerson@csc.ncsu.edu
}}


\maketitle

\begin{abstract}
We are proposing the \textsc{Fuse} corpus to be used as the data set for the MSR 2016 data challenge.
The \textsc{Fuse} corpus was presented at the MSR 2015 data showcase, containing \xlscount{} unique spreadsheets --- an order of magnitude larger than previous corpora.
In this paper we briefly revisit how the corpus was made, make a case for how this large quantity of spreadsheets will offer large benefits to the end-user and software engineering community and propose some promising lines of research.
We conclude with an overview of the tools we provide to aid researchers who will use our dataset for the challenge.

\end{abstract}


\IEEEpeerreviewmaketitle

\section{Introduction}

End-user programmers today constitute a broad class of users, including teachers, accountants, administrators, managers, research scientists, and even children~\cite{Ko2011}.
%
Although these users are typically not professional software developers, their roles routinely involve computational tasks that, in many ways, are similar to those of developers --- not just in activity, but also in their underlying cognitive demands on users~\cite{Blackwell2002}. 

Perhaps the most ubiquitous form~\cite{Scaffidi2005} of end-user programming software are \emph{spreadsheets}, a table-oriented visual interface that serves as the underlying model for the users' applications~\cite{Nardi1990}. \emph{Cells} within these tables are augmented with computation, such as expressions, functions and macros~\cite{Nardi1990}. 
This interplay between presentation and computation within the spreadsheet environment has garnered significant interest from the software engineering research community~\cite{Burnett2009}. 
Researchers have adopted techniques and approaches to studying errors~\cite{Powell2008}, code smells~\cite{Pinzger2012}, and refactoring in spreadsheets~\cite{Badame2012}, similar to traditional programming environments. 

% \footnote{``Spreadsheets are not just tools for doing ``what-if'' analysis. They provide a specific data structure: a table. Most Excel users never enter a formula. They use Excel when they need a table. The gridlines are the most important feature of Excel.'' \url{http://www.joelonsoftware.com/items/2012/01/06.html}}.

\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
\caption{Comparison of \textsc{Fuse} and other spreadsheet corpora\label{tab:corpora}}
\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
\begin{tabular}{llllll}
\toprule
 & \textbf{\textsc{Fuse}} & \textbf{EUSES} & \textbf{Enron} & \textbf{ClueWeb}\\
\midrule
Size ($n$) & 249,376 & 6,000 & 15,570 & 410,554\\
Space (GB) & 87  & 0.64 & 23.3 & 110\\
Access & All & Researchers & All & All\\
Unique formulas & 894,361 & 84,004 & 784,380  & --\\
Extendable & Yes & Yes & No & Yes\\
Framework & Hadoop & Excel/VBA & Scantool & \textsc{--}\\
Scalable & Yes & No & No & Yes\\
Collection period & 2013-2014 & 2006 & 2006 & 2009\\
Pri. origin & CC & Google & Enron & ClueWeb\\
Binaries & Yes  & Yes & Yes & No\\
Metadata & Yes & No & No & No\\
Domains & 4,318 & - & - & 51,157\\
Distinct functions & 219 & 209 & 139 & --\\
\bottomrule
\end{tabular}
\end{table}


To better understand end-user activities and design tools to assist end-users, researchers have responded by curating spreadsheet corpora to support spreadsheet studies~\cite{Fisher2005,Hermans2015,Chen2013}. 
%
This paper presents one such spreadsheet corpus, called \textsc{Fuse}, extracted from the over 26.83 billion web pages in the Common Crawl\footnote{The Common Crawl non-profit organization provides this index to companies and individuals at no cost for the purpose of research and analysis. For more information, see \url{http://www.commoncrawl.org}.} index. 
%
We believe that \textsc{Fuse} offers several useful traits not found in prior corpora (see Table \ref{tab:corpora}); 
for example, \textsc{Fuse} is obtained in such a way that researchers can independently reproduce an identical corpus from source materials.

% 2006: http://msr.uwaterloo.ca/challenge/
% 2007: http://msr.uwaterloo.ca/msr2007/challenge/
% 2008: http://msr.uwaterloo.ca/msr2008/
% 2009: http://msr.uwaterloo.ca/msr2009/
% 2010: http://msr.uwaterloo.ca/msr2010/index.html
% 2011: http://2011.msrconf.org/msr-challenge.html
% 2012: http://2012.msrconf.org/challenge.php
% 2013: http://2013.msrconf.org/challenge.php
% 2014: http://2014.msrconf.org/challenge.php
% 2015: http://2015.msrconf.org/challenge.php
\begin{table}[!t]
\caption{Previous MSR Challenge Data Sources\label{tab:datasources}}
\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
\begin{tabular}{ll}
\toprule
\textbf{\textsc{Year}} & \textbf{Data Source}\\
\midrule
2006 & PostgreSQL and ArgoUML\\
2007 & Eclipse and Firefox\\
2008 & Eclipse\\
2009 & GNOME Desktop\\
2010 & FreeBSD, Debian, and GNOME\\
2011 & Eclipse and NetBeans, Firefox and Chrome\\
2012 & Android\\
2013 & Stack Overflow\\
2014 & GitHub\\
2015 & Stack Overflow\\
\bottomrule
\end{tabular}
\end{table}

\section{Proposed MSR Challenge}

Given the increasing role and importance of end-user programmers, our proposed MSR challenge asks participants to obtain insights about end-user programmers and the artifacts that they produce using spreadsheets. Can we identify the types of artifacts that they create? What type of features do they use to develop these artifacts? What type of mistakes do they make?

Previous MSR challenges have been predominantly focused on the types of activities performed by professional programmers (see Table \ref{tab:datasources}). For example, years 2006 through 2011 of MSR challenges focused on source code repositories, bug data, and mailing lists for particular software projects. In 2012, the MSR challenge was extended to a different domain --- mobile devices --- but the sources of data to be considered were still essential change logs and bug reports. In more recent years, to increase diversity the MSR challenges have been expanding their data sets to broader information sources, such as Stack Overflow.

We propose that spreadsheet corpora, such as \textsc{Fuse}, serve as the data source for next year's challenge. First, we think that such a challenge would increase the diversity of the MSR community, by garnering interesting from researchers in the end-user communities. Second, spreadsheets may serve as a data source to allow software engineering researchers to try their tools and techniques, such as static analysis, on a very different domain than what they typically study. Finally, we hope that this MSR challenge will inspire new tools and generate new insights about end-user programmers, and that such findings will drive the research direction of future end-user research.

\section{The Origins of \textsc{Fuse}}

\subsection{The Common Crawl Web Index}

This data came from the Common Crawl web dump.

This paper presents one such spreadsheet corpus, called \textsc{Fuse}, extracted from the over 26.83 billion web pages in the Common Crawl. 
The Common Crawl non-profit organization provides this index to companies and individuals at no cost for the purpose of research and analysis\footnote{For more information, see \url{http://www.commoncrawl.org}}

\subsection{Extracting the spreadsheets from a 2 PB Index}

A brief overview of the previous paper


\section{Obtaining \textsc{Fuse} and Making Sense of It}

The data can be directly loaded from go.ncsu.edu/fuse.

The result, \textsc{Fuse}, is characterized through two, hierarchical datasets: a Web Analysis dataset, and a Binary Analysis dataset.

\textbf{Web Analysis:} This dataset contains \urlcount{} spreadsheet-related URLs and HTTP responses. 292,043 of these responses point to a unique URL, and the top domain is \texttt{.org} (29.5\%), followed by \texttt{.gov} (27.7\%). 
The analysis contains 6,316 distinct domain names. Unfortunately, relying solely on Web Analysis for spreadsheets will not result in a reproducible corpus, as the Internet is always in flux.

\textbf{Binary Analysis:}  Due to the fact that the content pointed to by the links in Web Analysis can change over time, the Binary Analysis dataset contains \xlscount{} unique spreadsheets, extracted directly from the raw data contained within Common Crawl archives, rather than the Internet. 
Since each monthly Common Crawl archive is a permanent snapshot in time, the spreadsheets in Binary Analysis are always reproducible.

We have augmented the Binary Analysis to also contain some metadata to help index the spreadsheets.

%If you really need to, you can take the deduped binary spreadsheet and expand them back into their full set. The first column of the fuse-dedup.map-dec2014.txt  file contains the WARC-Record-ID of the original spreadsheet. The second column contains the equivalent deduped WARC-Record-ID. Thus, for each record, one must simply copy the deduped file to the expanded file. There are any number of ways to do this:

%cat cc.dedup.map.txt | \ 
%awk '{print "src/" $2 "\n" "dst/" $1 "\n"}' | \ 
%xargs -n 2 cp

%\todo{tbarik} : look at the last 10 years of data challenges and make a table to show it's a bunch of the same

\section{Motivation for why the dataset is appropriate}

We believe this dataset is a good fit for MSR 2016 data challenge because in our initial analysis of the data, we noticed clues that these spreadsheets contain non-trivial programming, most of which is done by end-users.
[citation for end users being a non-neglible portion of the Software development community].  
Fuse offers a chance to shed some deep insights into the type of code end users find themselves needing to write.
For example, IF was the most common function used across all \xlscount{} spreadsheets, more common than SUM, AVERAGE, even basic operations like addition, subtraction, etc.
In 29.6\% of these uses of IF, formulas contained at least two IF clauses, in some cases nested 20 or more times in a single cell.
End user programmers are making actual software, and now we have a large corpus to see how they do it.

One additional motivation for why we think this dataset would make a good challenge paper is that the dataset is large enough that we, the curators, don't even have a good sense of what it entails.
This challenge will require participants to apply clever machine learning techniques at scale, which is something previous corpora haven't necesitated (The original Euses was analyzed on a laptop computer over the course of a few weeks with an Excel VB script.)
Additionally, we are fortunate to have these previous corpora to compare Fuse to (Euses, Enron), which opens up a dynamic range of analysis.


\section{A sample list of ways the data could be used}

There are many ways spreadsheets have been studied in the past.  
In this section, we present a few of them as well as a few of our own with the hope of sparking the minds of the creative MSR community.

One similarity that spreadsheet corpora have is that not every spreadsheet uses formulas.  
In fact, the proportion of formula-containing spreadsheets is typically less than half.
This has been noticed by even the developers of Excel:
\begin{displayquote}
Everybody thought of Excel as a financial modeling application, [but] we visited dozens of Excel customers, and did not see anyone using Excel to actually perform what you would call `calculations.' Almost all of them were using Excel because it was a convenient way to create a table.

 --- Joel Spolsky~\cite{JoelOnSoftware}
\end{displayquote}
The open question we have is \textbf{Can you detect spreadsheets that could use formulas but don't using techniques like machine learning?}
As far as we know, no one has directly answered this.

Several researchers have investigated techniques of determining the quality of spreadsheets through static analysis, using theoretically similar approaches to their software engineering counterparts.
For example, Cunha and colleagues have created a quality model of Spreadsheets~\cite{Cunha2012}.
The work by Pinzger and others introduced the idea of code smells to spreadsheets\cite{Pinzger2012}.
Most recently, Jannach and colleagues came up with a technique for automatically finding and fixing spreadsheet errors~\cite{jannach2014}.
One downside to these recent approaches is that they all relied on the well-known EUSES corpus~\cite{Fisher2005}, which contained about 5,000 spreadsheets from 2005.
It would be interesting to \textbf{replicate findings of these static analysis tools on \textsc{Fuse}}, and \textbf{to expand these techniques to include modern spreadsheet tools and functions}.

We found some spreadsheets that changed at least once over the course of the Common Crawl.
The fact that \textsc{Fuse} has this temporal component opens the door to literally a new dimension of analysis, such as \textbf{How do spreadsheets and their formulas change over time?}
We anticipate that researchers will be able to use a spreadsheet-diffing tool like SheetDiff created by Chambers and colleagues~\cite{chambers2010} to assist with answering this family of research questions.

The final set of research questions digs into the structure of spreadsheets and clustering or otherwise drawing conclusions about the set.
The work by Abraham and colleagues \cite{Abraham2006} looked at \textbf{what can you extrapolate about a spreadsheet based on its structure}, such as "This looks like a gradebook and this looks like an inventory".
Along this vein, \textbf{How likely are formulas to co-exist across sheets?} 
\textbf{Do some functions cluster together? }
\textbf{Can we do collaborative filtering or a similar technique and make recommendations to users? }
Small examples like those created by Le and Gulwani's Flash Extraction technique~\cite{le2014}.  


\section{Any research that has used the dataset or a similar dataset up to this point}
We made the data set available in March 2015.  

Since then, we have had tens of downloads and are currently aware of at least three researchers or research groups using Fuse.  
\footnote{Links to known researchers or research labs using Fuse: \url{http://emeryberger.com/research/}, \url{http://research.csc.ncsu.edu/dlf/}, and \url{http://www.felienne.com/}}



\section{Any other details the authors feel is appropriate}
Don't put this in ACM.  Make all references to the MSR data paper.

We intend this paper to be instructions for the MSR data challenge.  
However, we request that our msr 2015 paper be cited as a part of the challenge
\section{Short bio of the authors}


\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
\bibliography{library}

\end{document}
